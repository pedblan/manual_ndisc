# Workflow proposto (de ponta a ponta)

## 0) Objetivo & taxonomia (defina antes de codar)

- **Unidade de an√°lise:** span textual (trecho) dentro do discurso.  
- **R√≥tulos principais** (enum inicial, adapt√°vel ao Senado):  
  met√°fora, meton√≠mia, hip√©rbole, ironia, ant√≠tese, paradoxo, an√°fora (repeti√ß√£o no in√≠cio de frases), alitera√ß√£o (som inicial repetido), eufemismo, grada√ß√£o, prosopopeia, pergunta_ret√≥rica, cita√ß√£o_de_autoridade, apelo_popular, analogia, par√≥dia, sarcasmo.  
- Comece com ~10‚Äì12 r√≥tulos; refine depois do primeiro round.  
- **Sa√≠das por span:**  
  - `label`  
  - `start_char`  
  - `end_char`  
  - `text`  
  - `rationale` (breve justificativa)  
  - `cues` (pistas como ‚Äúcomparativo‚Äù, ‚Äúhip√©rbole num√©rica‚Äù)  
  - `confidence [0..1]`  

> üí° Dica: para *pergunta ret√≥rica* e *an√°fora*, d√° para combinar heur√≠sticas simples (pr√©-filtro) + LLM.

---

## 1) Prepara√ß√£o dos dados (SQLite ‚Üí chunks com offsets)

- **Sele√ß√£o:** pegue discursos com  
  ```sql
  Data BETWEEN '2007-01-01' AND '2024-12-31'
  ```
- **Chunking (token-aware):** janelas de ~1.5k‚Äì2k tokens com overlap (200‚Äì250 tokens).  
  Mantenha:
  - `chunk_id`  
  - `speech_id`  
  - `start_char_global`  
  - `end_char_global`  

- **Pr√©-filtros opcionais (baratinhos):**
  - Pergunta ret√≥rica ‚Üí frases com `?` e marcadores (‚Äúobviamente‚Ä¶‚Äù, ‚Äúpor acaso‚Ä¶‚Äù).  
  - An√°fora ‚Üí 2+ frases consecutivas come√ßando com a mesma locu√ß√£o.  
  - Alitera√ß√£o ‚Üí 4+ palavras pr√≥ximas com mesma inicial.  

Esses *flags* entram como **features no prompt**.

---

## 2) Structured Outputs ‚Äì desenhe o JSON Schema

Voc√™ for√ßa o modelo a devolver JSON no formato que voc√™ precisa.  

Esqueleto resumido:

```python
SCHEMA = {
  "name": "figuras_linguagem",
  "schema": {
    "type": "object",
    "properties": {
      "spans": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "label": {"type": "string", "enum": [
              "metafora","metonimia","hiperbole","ironia","antitese",
              "paradoxo","anafora","aliteracao","eufemismo","gradacao",
              "prosopopeia","pergunta_ret√≥rica","citacao_de_autoridade",
              "apelo_popular","analogia","parodia","sarcasmo"
            ]},
            "start_char": {"type": "integer", "minimum": 0},
            "end_char": {"type": "integer", "minimum": 0},
            "text": {"type": "string"},
            "rationale": {"type": "string"},
            "cues": {"type": "array", "items": {"type": "string"}},
            "confidence": {"type": "number", "minimum": 0, "maximum": 1}
          },
          "required": ["label","start_char","end_char","text","confidence"]
        }
      }
    },
    "required": ["spans"],
    "additionalProperties": False
  },
  "strict": True
}
```

---

## 3) Prompt (PT-BR, com pistas e ‚Äún√£o-alucinar‚Äù)

- **Sistema:** papel do modelo (‚Äúvoc√™ √© um linguista‚Ä¶‚Äù) + defini√ß√µes concisas de cada r√≥tulo.  
- **Instru√ß√µes:**
  - ‚ÄúExtraia apenas spans com alta evid√™ncia; se n√£o houver, retorne `spans: []`.‚Äù  
  - ‚ÄúUse offsets no texto do input abaixo (caracteres).‚Äù  
  - ‚ÄúEvite duplicatas (mesmo trecho com r√≥tulos diferentes s√≥ se de fato couber).‚Äù  
  - ‚ÄúAdote confidence conservador.‚Äù  

- **Few-shot:** 2‚Äì4 exemplos curtos em portugu√™s, input/output conforme o schema.  
- **Pr√©-filtros** entram como metadados:  
  ```json
  "flags": {"anafora_detectada": true, ...}
  ```

---

## 4) Chamada √† API (dev/local) com Structured Outputs

Pseudoc√≥digo minimalista:

```python
from openai import OpenAI
client = OpenAI()

resp = client.responses.create(
    model="gpt-4o-mini",  # compat√≠vel com Structured Outputs
    input=[{
        "role": "system", "content": SISTEMA_DEFINICOES
    },{
        "role": "user",
        "content": [
            {"type":"text", "text": f"[META] speech_id={sid}, chunk_id={cid}, start={start_char_global}"},
            {"type":"text", "text": TEXTO_DO_CHUNK}
        ]
    }],
    response_format={"type": "json_schema","json_schema": SCHEMA},
    temperature=0.0
)

data = resp.output[0].content[0].json
```

---

## 5) Escala: Batch API

- Gere `.jsonl` (uma requisi√ß√£o por linha).  
- Upload ‚Üí cria√ß√£o do job ‚Üí baixar output/error file.  
- Reconciliar offsets locais do chunk ‚Üí globais do discurso.  

---

## 6) Avalia√ß√£o: OpenAI Evals (+ golden set)

- **Golden set:** 150‚Äì300 spans em ~50 discursos.  
- **M√©tricas:**
  - Precis√£o / Recall / F1 por r√≥tulo (IoU ‚â• 0.5).  
  - Exact label match.  
  - Compliance ao schema.  

- **Grader LLM (opcional):** verificar se um span realmente expressa a figura.

---

## 7) P√≥s-processamento e entrega

- Normalizar spans duplicados (por overlap).  
- Persistir em tabela `Figuras (SQLite)`:
  ```
  id, speech_id, ano, label, start_char, end_char, text, rationale, confidence
  ```
- Agrega√ß√µes:
  - por ano e partido  
  - por tipo de sess√£o  
  - densidade por mil palavras  

- Visualiza√ß√£o: s√©ries temporais, facets, ranking de senadores/temas.  

---

## Esqueleto de c√≥digo

### A) Chunking com offsets
```python
def chunk_text(texto: str, max_chars: int = 6000, overlap: int = 800):
    chunks, i, n = [], 0, len(texto)
    while i < n:
        start, end = i, min(n, i + max_chars)
        chunks.append((start, end, texto[start:end]))
        i = end - overlap if end - overlap > i else end
    return chunks
```

### B) Gera√ß√£o de linhas para Batch (.jsonl)
```python
import json

def make_batch_lines(model, schema, prompt_sys, speech_id, chunk_id, text, meta):
    user_content = [
        {"type":"text","text": f"[META] {json.dumps(meta, ensure_ascii=False)}"},
        {"type":"text","text": text}
    ]
    body = {
        "model": model,
        "input": [
            {"role":"system","content": prompt_sys},
            {"role":"user","content": user_content}
        ],
        "response_format": {"type":"json_schema","json_schema": schema},
        "temperature": 0.0
    }
    return {
        "custom_id": f"{speech_id}:{chunk_id}",
        "method": "POST",
        "url": "/v1/responses",
        "body": body
    }

def write_jsonl(lines, path):
    with open(path, "w", encoding="utf-8") as f:
        for ln in lines:
            f.write(json.dumps(ln, ensure_ascii=False) + "\n")
```

### C) Reconcilia√ß√£o de offsets
```python
def remap_offsets(spans, chunk_start):
    for s in spans:
        s["start_char"] += chunk_start
        s["end_char"]   += chunk_start
    return spans
```

### D) M√©trica IoU para spans
```python
def iou_span(a, b):
    inter = max(0, min(a["end_char"], b["end_char"]) - max(a["start_char"], b["start_char"]))
    uni = (a["end_char"] - a["start_char"]) + (b["end_char"] - b["start_char"]) - inter
    return inter / uni if uni else 0.0
```

---

## Boas pr√°ticas & pegadinhas

- Modelos compat√≠veis com **Structured Outputs**.  
- Evitar ‚Äúfor√ßar‚Äù alucina√ß√µes ‚Üí permitir `spans: []`.  
- Produ√ß√£o: `temperature=0`.  
- Rodar Evals antes de escalar.  
- Batch: agrupar por tamanho similar, monitorar `error file`.  

---

## Como come√ßar em 1 dia (plano rel√¢mpago)

1. Definir r√≥tulos + 4 exemplos few-shot.  
2. Criar schema e rodar 50 chunks via Responses.  
3. Medir tempo/custo.  
4. Montar golden set (~50 trechos rotulados).  
5. Subir Batch com 2‚Äì5k chunks.  
6. Rodar Evals e reportar P/R/F1.  

---

## Refer√™ncias oficiais

- [Structured Outputs](https://platform.openai.com)  
- [Text generation](https://platform.openai.com)  
- [Responses API](https://platform.openai.com)  
- [Batch API](https://platform.openai.com)  
- [Evals](https://platform.openai.com)
